# Sistema RAG Local com Python, LangChain e Neo4j

## Vis√£o Geral

Este projeto implementa um sistema de Retrieval-Augmented Generation (RAG) local usando Python, LangChain e Neo4j como banco de dados vetorial e de grafos. O sistema permite ingest√£o, indexa√ß√£o e recupera√ß√£o de documentos para gerar respostas contextualizadas usando modelos de linguagem.

## Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Documentos    ‚îÇ    ‚îÇ   Processamento ‚îÇ    ‚îÇ   Armazenamento ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ PDFs          ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Text Splitter ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Neo4j         ‚îÇ
‚îÇ ‚Ä¢ TXTs          ‚îÇ    ‚îÇ ‚Ä¢ Embeddings    ‚îÇ    ‚îÇ ‚Ä¢ Vetores       ‚îÇ
‚îÇ ‚Ä¢ Webpages      ‚îÇ    ‚îÇ ‚Ä¢ Metadados     ‚îÇ    ‚îÇ ‚Ä¢ Relacionamentos‚îÇ
‚îÇ ‚Ä¢ APIs          ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ   Interface     ‚îÇ    ‚îÇ   Gera√ß√£o       ‚îÇ           ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ           ‚îÇ
‚îÇ ‚Ä¢ API REST      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ ‚Ä¢ LLM Local     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ ‚Ä¢ Streamlit UI  ‚îÇ    ‚îÇ ‚Ä¢ Prompt Eng.   ‚îÇ
‚îÇ ‚Ä¢ CLI           ‚îÇ    ‚îÇ ‚Ä¢ Context       ‚îÇ
‚îÇ ‚Ä¢ MCP Server    ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Componentes Principais

### 1. M√≥dulo de Ingest√£o (`ingestion/`)
- **Document Loaders**: Carregamento de diferentes tipos de documentos
- **Text Splitters**: Divis√£o inteligente de documentos em chunks
- **Metadata Extractors**: Extra√ß√£o de metadados relevantes

### 2. M√≥dulo de Embedding (`embedding/`)
- **Embedding Models**: Modelos locais para vetoriza√ß√£o (sentence-transformers)
- **Vector Store**: Interface com Neo4j para armazenamento de vetores
- **Similarity Search**: Busca por similaridade sem√¢ntica

### 3. M√≥dulo de Retrieval (`retrieval/`)
- **Semantic Search**: Busca sem√¢ntica usando embeddings
- **Graph Traversal**: Navega√ß√£o por relacionamentos no Neo4j
- **Hybrid Search**: Combina√ß√£o de busca vetorial e de grafos
- **Re-ranking**: Refinamento dos resultados recuperados

### 4. M√≥dulo de Generation (`generation/`)
- **LLM Integration**: Interface com modelos locais (Ollama, llama.cpp)
- **Prompt Templates**: Templates otimizados para RAG
- **Context Management**: Gerenciamento de contexto e mem√≥ria
- **Response Synthesis**: S√≠ntese de respostas baseadas no contexto

### 5. Base de Dados (`database/`)
- **Neo4j Setup**: Configura√ß√£o e inicializa√ß√£o do banco
- **Schema Definition**: Defini√ß√£o de n√≥s e relacionamentos
- **Query Interface**: Interface para consultas Cypher
- **Vector Indexing**: Configura√ß√£o de √≠ndices vetoriais

## Fluxo de Dados

### Ingest√£o de Documentos
1. **Upload/Input** ‚Üí Recebimento de documentos
2. **Parsing** ‚Üí Extra√ß√£o de texto e metadados
3. **Chunking** ‚Üí Divis√£o em segmentos sem√¢nticos
4. **Embedding** ‚Üí Convers√£o em vetores
5. **Storage** ‚Üí Armazenamento no Neo4j com relacionamentos

### Consulta e Resposta
1. **Query Input** ‚Üí Recebimento da pergunta do usu√°rio
2. **Query Embedding** ‚Üí Vetoriza√ß√£o da consulta
3. **Retrieval** ‚Üí Busca h√≠brida (vetorial + grafo)
4. **Context Assembly** ‚Üí Montagem do contexto relevante
5. **Generation** ‚Üí Gera√ß√£o de resposta pelo LLM
6. **Response** ‚Üí Retorno da resposta contextualizada

## Requisitos T√©cnicos

### Depend√™ncias Python
```
langchain>=0.1.0
langchain-community>=0.0.10
neo4j>=5.0.0
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
fastapi>=0.100.0
uvicorn>=0.22.0
python-multipart>=0.0.6
aiofiles>=23.0.0
mcp>=1.0.0
streamlit>=1.28.0
plotly>=5.15.0
st-aggrid>=0.3.4
ollama>=0.1.0
python-dotenv>=1.0.0
```

### Infraestrutura
- **Python**: 3.9+
- **Neo4j**: 5.0+ (Community ou Enterprise)
- **Mem√≥ria RAM**: M√≠nimo 8GB (recomendado 16GB+)
- **Armazenamento**: 10GB+ para modelos e dados
- **GPU**: Opcional (acelera embeddings e LLM)

### Modelos Locais
- **Embeddings**: 
  - **Ollama nomic-embed-text** (modelo principal recomendado)
  - sentence-transformers/all-MiniLM-L6-v2 (multil√≠ngue)
  - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
- **LLM**:
  - **Ollama qwen2:8b** (modelo principal recomendado)
  - Ollama (llama2, mistral, codellama, llama3)
  - llama.cpp com modelos GGUF
  - Transformers locais (Llama 2, Mistral)

## Estrutura do Projeto

```
local_rag/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py
‚îÇ   ‚îî‚îÄ‚îÄ neo4j_config.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loaders.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ splitters.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ semantic_search.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_search.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hybrid_search.py
‚îÇ   ‚îú‚îÄ‚îÄ generation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ context.py
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neo4j_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.py
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ mcp/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handlers.py
‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ streamlit_app.py
‚îÇ       ‚îú‚îÄ‚îÄ pages/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 01_document_upload.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 02_query_interface.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 03_document_manager.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ 04_system_status.py
‚îÇ       ‚îî‚îÄ‚îÄ components/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ file_uploader.py
‚îÇ           ‚îú‚îÄ‚îÄ query_interface.py
‚îÇ           ‚îî‚îÄ‚îÄ document_viewer.py
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_neo4j.py
‚îÇ   ‚îî‚îÄ‚îÄ ingest_documents.py
‚îî‚îÄ‚îÄ docs/
```

## Instala√ß√£o e Configura√ß√£o

### 1. Ambiente Python
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

### 2. Neo4j Setup
```bash
# Docker (recomendado)
docker run \
    -p 7474:7474 -p 7687:7687 \
    -e NEO4J_AUTH=neo4j/password \
    -e NEO4J_PLUGINS=["graph-data-science","apoc"] \
    neo4j:5.15-community
```

### 3. Configura√ß√£o

#### 3.1 Configura√ß√£o B√°sica
```bash
cp .env.example .env
# Editar configura√ß√µes no arquivo .env se necess√°rio
```

#### 3.2 Configura√ß√£o OpenAI (Opcional)
Para embeddings mais r√°pidos, configure sua API key do OpenAI:

```bash
# M√©todo 1: Vari√°vel de ambiente (recomendado)
export OPENAI_API_KEY="sk-your-openai-key-here"

# M√©todo 2: Arquivo .env
echo "OPENAI_API_KEY=sk-your-openai-key-here" >> .env

# M√©todo 3: Definir ao executar
OPENAI_API_KEY="sk-your-key" streamlit run streamlit_app.py
```

**Obter API Key**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

#### 3.3 Verificar Configura√ß√£o
```bash
python scripts/check_config.py
```

### 4. Ollama Setup
```bash
# Instalar Ollama (macOS/Linux)
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar modelo de embedding
ollama pull nomic-embed-text

# Baixar modelo LLM (qwen2:8b j√° dispon√≠vel)
ollama pull qwen2:8b
```

### 5. Executar Interface Streamlit
```bash
streamlit run streamlit_app.py
```

## Op√ß√µes de Embedding

O sistema suporta dois tipos de embeddings para processamento de documentos:

### üè† Local (Ollama) - Padr√£o
- **Vantagens**: Totalmente privado, sem envio de dados externos, gratuito
- **Desvantagens**: Mais lento, requer recursos computacionais locais
- **Uso**: Ideal para dados sens√≠veis ou quando privacidade √© prioridade

### ‚òÅÔ∏è OpenAI
- **Vantagens**: Muito mais r√°pido, embeddings de alta qualidade
- **Desvantagens**: Requer API key (paga), dados enviados para OpenAI
- **Uso**: Ideal quando velocidade √© prioridade e dados n√£o s√£o sens√≠veis

### üí¨ Consultas
**Importante**: Independente do tipo de embedding escolhido, **todas as consultas sempre usam o modelo local** (qwen2:8b via Ollama). Apenas o processamento inicial de documentos pode usar OpenAI.

## Vantagens da Arquitetura

### Neo4j como Vector Store
- **Relacionamentos**: Mant√©m conex√µes sem√¢nticas entre documentos
- **Consultas Complexas**: Cypher para queries sofisticadas
- **Escalabilidade**: Suporte a grandes volumes de dados
- **Flexibilidade**: Schema flex√≠vel para diferentes tipos de documentos

### LangChain Integration
- **Modularidade**: Componentes reutiliz√°veis e test√°veis
- **Extensibilidade**: F√°cil adi√ß√£o de novos loaders e LLMs
- **Padroniza√ß√£o**: Interface consistente entre componentes
- **Comunidade**: Ecossistema rico de integra√ß√µes

### Execu√ß√£o Local
- **Privacidade**: Dados permanecem locais
- **Controle**: Controle total sobre modelos e processamento
- **Custos**: Sem custos de API externa
- **Lat√™ncia**: Respostas mais r√°pidas

## Casos de Uso

1. **Base de Conhecimento Corporativa**
2. **Assistente de Documenta√ß√£o T√©cnica**
3. **Sistema de FAQ Inteligente**
4. **An√°lise de Documentos Jur√≠dicos**
5. **Pesquisa Acad√™mica e Cient√≠fica**

## Interface MCP (Model Context Protocol)

### Vis√£o Geral
O sistema inclui um servidor MCP que permite integra√ß√£o direta com agentes de IA (como Claude Code, GPT-4, etc.), fornecendo acesso √†s funcionalidades RAG atrav√©s de tools padronizadas.

### Arquitetura MCP
```mermaid
graph LR
    A[Agente AI] --> B[MCP Client]
    B --> C[MCP Server Local]
    C --> D[RAG System]
    D --> E[Neo4j Database]
    D --> F[Local LLM]
```

### Tools Dispon√≠veis

#### 1. Query Tools
- **`rag_query`**: Consulta principal do sistema RAG
  - Entrada: pergunta do usu√°rio, contexto opcional
  - Sa√≠da: resposta com fontes e metadados
  - Par√¢metros: `query` (str), `max_results` (int), `include_sources` (bool)

- **`semantic_search`**: Busca sem√¢ntica pura
  - Entrada: texto de consulta
  - Sa√≠da: documentos similares com scores
  - Par√¢metros: `text` (str), `k` (int), `threshold` (float)

#### 2. Document Management Tools
- **`ingest_document`**: Adiciona novo documento ao sistema
  - Entrada: caminho do arquivo ou texto
  - Sa√≠da: confirma√ß√£o e ID do documento
  - Par√¢metros: `source` (str), `metadata` (dict), `chunk_size` (int)

- **`list_documents`**: Lista documentos indexados
  - Entrada: filtros opcionais
  - Sa√≠da: lista de documentos com metadados
  - Par√¢metros: `limit` (int), `filters` (dict)

- **`delete_document`**: Remove documento do √≠ndice
  - Entrada: ID do documento
  - Sa√≠da: confirma√ß√£o de remo√ß√£o
  - Par√¢metros: `doc_id` (str)

#### 3. System Management Tools
- **`get_system_status`**: Status do sistema RAG
  - Entrada: nenhuma
  - Sa√≠da: status dos componentes (Neo4j, LLM, etc.)

- **`update_embeddings`**: Atualiza embeddings existentes
  - Entrada: modelo opcional
  - Sa√≠da: progresso da atualiza√ß√£o
  - Par√¢metros: `model_name` (str), `batch_size` (int)

### Configura√ß√£o MCP

#### 1. Servidor MCP Local
```python
# src/mcp/server.py
from mcp.server import Server
from mcp.types import Tool, TextContent, Resource

class RAGMCPServer:
    def __init__(self, rag_system):
        self.server = Server("local-rag")
        self.rag = rag_system
        self._register_tools()
    
    def _register_tools(self):
        # Registra todas as tools MCP
        pass
```

#### 2. Configura√ß√£o do Cliente
```json
{
  "mcpServers": {
    "local-rag": {
      "command": "python",
      "args": ["-m", "src.mcp.server"],
      "cwd": "/path/to/local_rag"
    }
  }
}
```

### Integra√ß√£o com Agentes AI

#### Claude Code
```bash
# Adicionar ao settings.json do Claude Code
{
  "mcp": {
    "servers": {
      "local-rag": {
        "command": "python",
        "args": ["-m", "src.mcp.server"],
        "cwd": "/Users/roger.silva/local_rag"
      }
    }
  }
}
```

#### OpenAI GPT
```python
from openai import OpenAI
from mcp.client import Client

# Conecta ao servidor MCP local
mcp_client = Client("local-rag")
openai_client = OpenAI()

# Usa tools MCP no GPT
tools = mcp_client.list_tools()
```

### Exemplo de Uso

```python
# Agente consulta via MCP
query_result = await mcp_client.call_tool(
    "rag_query",
    {
        "query": "Como funciona o sistema de embeddings?",
        "max_results": 5,
        "include_sources": True
    }
)

# Resposta estruturada
{
    "answer": "O sistema de embeddings utiliza...",
    "sources": [
        {
            "document": "embeddings_doc.pdf",
            "chunk": "p√°gina 15-16",
            "score": 0.89
        }
    ],
    "metadata": {
        "processing_time": 0.45,
        "model_used": "ollama/nomic-embed-text"
    }
}
```

### Vantagens do MCP

#### Para Agentes AI
- **Acesso Direto**: Tools nativas para consulta RAG
- **Contexto Rico**: Metadados e fontes inclu√≠dos automaticamente
- **Tipagem**: Schemas bem definidos para entradas/sa√≠das
- **Performance**: Conex√£o local sem lat√™ncia de rede

#### Para Desenvolvedores
- **Padroniza√ß√£o**: Interface consistente entre diferentes agentes
- **Extensibilidade**: F√°cil adi√ß√£o de novas tools
- **Debugging**: Logs detalhados de todas as intera√ß√µes
- **Seguran√ßa**: Controle total sobre acesso e permiss√µes

### Casos de Uso MCP

1. **Assistente de C√≥digo**: Consultar documenta√ß√£o t√©cnica via Claude Code
2. **Research Assistant**: GPT-4 com acesso √† base de conhecimento local
3. **Content Generation**: Agentes criativos com contexto espec√≠fico
4. **Data Analysis**: Agentes anal√≠ticos consultando documentos corporativos
5. **Customer Support**: Chatbots com acesso √† KB interna

## Interface Streamlit

### Vis√£o Geral
Interface web local constru√≠da com Streamlit para facilitar o uso do sistema RAG atrav√©s de uma interface gr√°fica intuitiva. Permite upload de documentos, consultas interativas e gerenciamento do sistema.

### Funcionalidades Principais

#### 1. P√°gina de Upload de Documentos (`01_document_upload.py`)
- **Upload de Arquivos**: Interface drag-and-drop para m√∫ltiplos formatos
  - Suporte: PDF, TXT, DOCX, MD, CSV, JSON
  - Upload individual ou em lote
  - Preview do conte√∫do antes do processamento
- **Configura√ß√µes de Processamento**: 
  - Tamanho de chunks personaliz√°vel
  - Sobreposi√ß√£o entre chunks
  - Sele√ß√£o de modelo de embedding
- **Metadados**: Adi√ß√£o de tags, categorias e descri√ß√µes
- **Progresso**: Barra de progresso durante ingest√£o
- **Valida√ß√£o**: Verifica√ß√£o de formatos e tamanhos

#### 2. Interface de Consulta (`02_query_interface.py`)
- **Chat Interface**: Interface de chat para consultas naturais
  - Hist√≥rico de conversa√ß√£o persistente
  - Respostas com formata√ß√£o rica (markdown)
  - Cita√ß√µes autom√°ticas com links para fontes
- **Configura√ß√µes de Busca**:
  - N√∫mero de documentos para retrieval
  - Threshold de similaridade
  - Tipo de busca (sem√¢ntica, h√≠brida, por grafo)
- **Filtros Avan√ßados**:
  - Por data de cria√ß√£o
  - Por tipo de documento
  - Por tags/categorias
- **Export de Conversas**: Download em PDF ou JSON

#### 3. Gerenciador de Documentos (`03_document_manager.py`)
- **Lista de Documentos**: Visualiza√ß√£o tabular com filtros
  - Informa√ß√µes: nome, tipo, tamanho, data de ingest√£o
  - Status de processamento
  - M√©tricas de uso (n√∫mero de consultas)
- **A√ß√µes por Documento**:
  - Visualizar conte√∫do e chunks
  - Editar metadados
  - Reprocessar com novos par√¢metros
  - Excluir do √≠ndice
- **Busca e Filtros**: Busca textual e filtros por metadados
- **Estat√≠sticas**: Gr√°ficos de distribui√ß√£o por tipo, tamanho, etc.

#### 4. Status do Sistema (`04_system_status.py`)
- **Monitoring Dashboard**: Pain√©is de monitoramento em tempo real
  - Status do Neo4j (conex√£o, espa√ßo, performance)
  - Status dos modelos (LLM, embeddings)
  - M√©tricas de uso (consultas/hora, tempo de resposta)
- **Recursos do Sistema**:
  - Uso de CPU, RAM e disco
  - Estat√≠sticas do banco de dados
  - Log de atividades recentes
- **Configura√ß√µes**: Interface para ajustar par√¢metros do sistema
- **Backup/Restore**: Ferramentas para backup dos dados

### Componentes Reutiliz√°veis

#### File Uploader (`components/file_uploader.py`)
```python
def enhanced_file_uploader():
    # Widget customizado para upload com preview
    # Valida√ß√£o de formatos e tamanhos
    # Extra√ß√£o autom√°tica de metadados
    pass
```

#### Query Interface (`components/query_interface.py`)
```python
def chat_interface():
    # Interface de chat com hist√≥rico
    # Formata√ß√£o de respostas
    # Integra√ß√£o com sistema RAG
    pass
```

#### Document Viewer (`components/document_viewer.py`)
```python
def document_viewer(doc_id):
    # Visualiza√ß√£o de documentos
    # Navega√ß√£o por chunks
    # Highlight de termos de busca
    pass
```

### Layout e Navega√ß√£o

#### Sidebar Principal
- **Navigation Menu**: Links para todas as p√°ginas
- **System Status**: Indicadores r√°pidos de status
- **Quick Actions**: A√ß√µes frequentes (nova consulta, upload)
- **User Settings**: Prefer√™ncias e configura√ß√µes

#### Layout Responsivo
- **Mobile-Friendly**: Interface adaptada para dispositivos m√≥veis
- **Themes**: Suporte a tema claro/escuro
- **Customiza√ß√£o**: Layout personaliz√°vel por usu√°rio

### Integra√ß√£o com Backend

#### API Connections
```python
# src/ui/streamlit_app.py
import streamlit as st
from src.api.client import RAGClient

@st.cache_resource
def get_rag_client():
    return RAGClient("http://localhost:8000")

# Uso em p√°ginas
client = get_rag_client()
result = client.query("pergunta do usu√°rio")
```

#### Session State Management
- **User Sessions**: Gerenciamento de estado por usu√°rio
- **Cache Strategy**: Cache inteligente para performance
- **Error Handling**: Tratamento robusto de erros

### Exemplo de Uso Completo

```python
# Fluxo t√≠pico do usu√°rio:
1. Acessa http://localhost:8501
2. Upload de documentos via drag-and-drop
3. Configura√ß√£o de processamento
4. Monitoramento do progresso de ingest√£o
5. Navega√ß√£o para interface de consulta
6. Realiza√ß√£o de perguntas em linguagem natural
7. Visualiza√ß√£o de respostas com fontes
8. Gerenciamento de documentos indexados
```

### Vantagens da Interface Streamlit

#### Para Usu√°rios Finais
- **Facilidade de Uso**: Interface intuitiva sem necessidade de c√≥digo
- **Feedback Visual**: Progresso e status em tempo real
- **Interatividade**: Widgets responsivos e preview instant√¢neo
- **Acessibilidade**: Interface web acess√≠vel via browser

#### Para Desenvolvedores
- **Desenvolvimento R√°pido**: Prototipagem r√°pida de interfaces
- **Integra√ß√£o Simples**: Conecta facilmente com backend Python
- **Customiza√ß√£o**: Componentes personaliz√°veis
- **Deploy Simples**: Execu√ß√£o local com um comando

## Pr√≥ximos Passos

1. Implementar m√≥dulos core (ingest√£o, embedding, retrieval)
2. Configurar conex√£o com Neo4j
3. **Integrar Ollama com nomic-embed-text para embeddings**
4. Desenvolver API REST
5. **Implementar interface Streamlit completa**
6. **Implementar servidor MCP com tools essenciais**
7. **Configurar integra√ß√£o com Claude Code**
8. Implementar testes unit√°rios
9. Otimizar performance e escalabilidade

### Configura√ß√£o Ollama para Embeddings

#### Modelos Configurados

##### nomic-embed-text (Embeddings)
- **Alta Performance**: Modelo otimizado para embeddings sem√¢nticos
- **Multil√≠ngue**: Suporte nativo para portugu√™s e outros idiomas
- **Contexto Longo**: Capacidade de processar textos extensos
- **Execu√ß√£o Local**: Processamento totalmente offline
- **Baixo Consumo**: Eficiente em recursos computacionais

##### qwen2:8b (LLM)
- **Modelo Avan√ßado**: Baseado na arquitetura Qwen 2.0
- **8B Par√¢metros**: Equilibrio entre performance e recursos
- **Multil√≠ngue**: Excelente suporte para portugu√™s
- **Racioc√≠nio**: Capacidades avan√ßadas de an√°lise e s√≠ntese
- **Contexto**: Window de 4096 tokens configur√°vel

#### Integra√ß√£o com o Sistema
```python
# src/embedding/ollama_embeddings.py
import ollama
from typing import List

class OllamaEmbeddings:
    def __init__(self, model_name: str = "nomic-embed-text"):
        self.model_name = model_name
        self.client = ollama.Client()
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for text in texts:
            response = self.client.embeddings(
                model=self.model_name,
                prompt=text
            )
            embeddings.append(response['embedding'])
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        response = self.client.embeddings(
            model=self.model_name,
            prompt=text
        )
        return response['embedding']
```

#### Configura√ß√£o no Sistema
```python
# config/settings.py
import os
from dotenv import load_dotenv

# Carrega vari√°veis do arquivo .env
load_dotenv()

# Configura√ß√µes Ollama
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "nomic-embed-text")
LLM_MODEL = os.getenv("LLM_MODEL", "qwen2:8b")

# Configura√ß√µes de embedding
EMBEDDING_CONFIG = {
    "provider": "ollama",
    "model": EMBEDDING_MODEL,
    "dimension": int(os.getenv("EMBEDDING_DIMENSION", 768)),
    "batch_size": int(os.getenv("EMBEDDING_BATCH_SIZE", 32)),
    "max_retries": int(os.getenv("EMBEDDING_MAX_RETRIES", 3))
}

# Configura√ß√µes de LLM
LLM_CONFIG = {
    "provider": "ollama",
    "model": LLM_MODEL,
    "temperature": float(os.getenv("LLM_TEMPERATURE", 0.1)),
    "max_tokens": int(os.getenv("LLM_MAX_TOKENS", 2048)),
    "context_window": int(os.getenv("LLM_CONTEXT_WINDOW", 4096))
}

# Configura√ß√µes Neo4j
NEO4J_CONFIG = {
    "uri": os.getenv("NEO4J_URI", "bolt://localhost:7687"),
    "username": os.getenv("NEO4J_USERNAME", "neo4j"),
    "password": os.getenv("NEO4J_PASSWORD", "password"),
    "database": os.getenv("NEO4J_DATABASE", "neo4j")
}
```

#### Arquivo .env
```bash
# Modelos Ollama configurados
EMBEDDING_MODEL=nomic-embed-text
LLM_MODEL=qwen2:8b

# URLs e configura√ß√µes
OLLAMA_BASE_URL=http://localhost:11434
NEO4J_URI=bolt://localhost:7687
NEO4J_PASSWORD=password

# Par√¢metros de processamento
EMBEDDING_DIMENSION=768
LLM_TEMPERATURE=0.1
DEFAULT_CHUNK_SIZE=1000
```

## Padr√£o de Arquitetura

### Vis√£o Geral Arquitetural

O sistema RAG Local segue uma **Arquitetura Hexagonal (Ports and Adapters)** combinada com **Domain-Driven Design (DDD)** e princ√≠pios **SOLID**, garantindo:

- **Separa√ß√£o de responsabilidades** entre camadas
- **Baixo acoplamento** e **alta coes√£o**
- **Testabilidade** e **manutenibilidade**
- **Flexibilidade** para mudan√ßas de tecnologia
- **Escalabilidade** horizontal e vertical

### Camadas da Arquitetura

```mermaid
graph TB
    subgraph "Presentation Layer"
        UI[Streamlit UI]
        API[FastAPI REST]
        MCP[MCP Server]
        CLI[CLI Interface]
    end
    
    subgraph "Application Layer"
        UC[Use Cases]
        APP[Application Services]
        DTOs[DTOs]
        COORD[Coordinators]
    end
    
    subgraph "Domain Layer"
        ENT[Entities]
        VO[Value Objects]
        DOM[Domain Services]
        REPO[Repository Interfaces]
    end
    
    subgraph "Infrastructure Layer"
        NEO[Neo4j Adapter]
        OLL[Ollama Adapter]
        FS[File System]
        CACHE[Cache]
    end
    
    UI --> UC
    API --> UC
    MCP --> UC
    CLI --> UC
    
    UC --> DOM
    APP --> DOM
    
    DOM --> REPO
    REPO --> NEO
    REPO --> OLL
    REPO --> FS
```

#### 1. Presentation Layer (Camada de Apresenta√ß√£o)

**Responsabilidade**: Interface com usu√°rios e sistemas externos

```python
# Estrutura da camada
src/presentation/
‚îú‚îÄ‚îÄ streamlit/          # Interface web Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îú‚îÄ‚îÄ api/               # API REST FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îú‚îÄ‚îÄ mcp/               # Servidor MCP
‚îÇ   ‚îú‚îÄ‚îÄ server.py
‚îÇ   ‚îî‚îÄ‚îÄ tools/
‚îî‚îÄ‚îÄ cli/               # Interface CLI
    ‚îú‚îÄ‚îÄ main.py
    ‚îî‚îÄ‚îÄ commands/
```

**Padr√µes aplicados**:
- **Controller Pattern**: Controle de requisi√ß√µes HTTP
- **Command Pattern**: Comandos CLI estruturados
- **Facade Pattern**: Simplifica√ß√£o de interfaces complexas

#### 2. Application Layer (Camada de Aplica√ß√£o)

**Responsabilidade**: Orquestra√ß√£o de casos de uso e coordena√ß√£o entre dom√≠nios

```python
# Estrutura da camada
src/application/
‚îú‚îÄ‚îÄ use_cases/         # Casos de uso espec√≠ficos
‚îÇ   ‚îú‚îÄ‚îÄ document_ingestion.py
‚îÇ   ‚îú‚îÄ‚îÄ semantic_search.py
‚îÇ   ‚îú‚îÄ‚îÄ rag_query.py
‚îÇ   ‚îî‚îÄ‚îÄ document_management.py
‚îú‚îÄ‚îÄ services/          # Servi√ßos de aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py
‚îÇ   ‚îú‚îÄ‚îÄ chunking_service.py
‚îÇ   ‚îî‚îÄ‚îÄ generation_service.py
‚îú‚îÄ‚îÄ dtos/              # Data Transfer Objects
‚îÇ   ‚îú‚îÄ‚îÄ document_dto.py
‚îÇ   ‚îú‚îÄ‚îÄ query_dto.py
‚îÇ   ‚îî‚îÄ‚îÄ response_dto.py
‚îî‚îÄ‚îÄ coordinators/      # Coordenadores de fluxo
    ‚îú‚îÄ‚îÄ ingestion_coordinator.py
    ‚îî‚îÄ‚îÄ query_coordinator.py
```

**Padr√µes aplicados**:
- **Use Case Pattern**: Encapsulamento de regras de neg√≥cio
- **Service Layer Pattern**: Servi√ßos de aplica√ß√£o
- **DTO Pattern**: Transfer√™ncia de dados entre camadas
- **Coordinator Pattern**: Orquestra√ß√£o de opera√ß√µes complexas

#### 3. Domain Layer (Camada de Dom√≠nio)

**Responsabilidade**: L√≥gica de neg√≥cio central e regras do dom√≠nio

```python
# Estrutura da camada
src/domain/
‚îú‚îÄ‚îÄ entities/          # Entidades do dom√≠nio
‚îÇ   ‚îú‚îÄ‚îÄ document.py
‚îÇ   ‚îú‚îÄ‚îÄ chunk.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py
‚îÇ   ‚îî‚îÄ‚îÄ query_result.py
‚îú‚îÄ‚îÄ value_objects/     # Objetos de valor
‚îÇ   ‚îú‚îÄ‚îÄ document_id.py
‚îÇ   ‚îú‚îÄ‚îÄ similarity_score.py
‚îÇ   ‚îî‚îÄ‚îÄ chunk_metadata.py
‚îú‚îÄ‚îÄ services/          # Servi√ßos de dom√≠nio
‚îÇ   ‚îú‚îÄ‚îÄ similarity_calculator.py
‚îÇ   ‚îú‚îÄ‚îÄ text_processor.py
‚îÇ   ‚îî‚îÄ‚îÄ relevance_ranker.py
‚îú‚îÄ‚îÄ repositories/      # Interfaces de reposit√≥rios
‚îÇ   ‚îú‚îÄ‚îÄ document_repository.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding_repository.py
‚îÇ   ‚îî‚îÄ‚îÄ vector_store_repository.py
‚îî‚îÄ‚îÄ events/            # Eventos de dom√≠nio
    ‚îú‚îÄ‚îÄ document_ingested.py
    ‚îî‚îÄ‚îÄ query_executed.py
```

**Padr√µes aplicados**:
- **Entity Pattern**: Objetos com identidade
- **Value Object Pattern**: Objetos imut√°veis sem identidade
- **Repository Pattern**: Abstra√ß√£o de persist√™ncia
- **Domain Service Pattern**: L√≥gica que n√£o pertence a entidades
- **Domain Events Pattern**: Comunica√ß√£o ass√≠ncrona

#### 4. Infrastructure Layer (Camada de Infraestrutura)

**Responsabilidade**: Implementa√ß√£o t√©cnica e integra√ß√£o com sistemas externos

```python
# Estrutura da camada
src/infrastructure/
‚îú‚îÄ‚îÄ persistence/       # Persist√™ncia de dados
‚îÇ   ‚îú‚îÄ‚îÄ neo4j/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mappers/
‚îÇ   ‚îî‚îÄ‚îÄ cache/
‚îÇ       ‚îú‚îÄ‚îÄ redis_cache.py
‚îÇ       ‚îî‚îÄ‚îÄ memory_cache.py
‚îú‚îÄ‚îÄ external/          # Servi√ßos externos
‚îÇ   ‚îú‚îÄ‚îÄ ollama/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_service.py
‚îÇ   ‚îî‚îÄ‚îÄ file_system/
‚îÇ       ‚îú‚îÄ‚îÄ document_loader.py
‚îÇ       ‚îî‚îÄ‚îÄ file_processor.py
‚îú‚îÄ‚îÄ messaging/         # Mensageria e eventos
‚îÇ   ‚îú‚îÄ‚îÄ event_bus.py
‚îÇ   ‚îî‚îÄ‚îÄ handlers/
‚îî‚îÄ‚îÄ monitoring/        # Observabilidade
    ‚îú‚îÄ‚îÄ metrics.py
    ‚îú‚îÄ‚îÄ logging.py
    ‚îî‚îÄ‚îÄ health_check.py
```

**Padr√µes aplicados**:
- **Adapter Pattern**: Integra√ß√£o com sistemas externos
- **Factory Pattern**: Cria√ß√£o de objetos complexos
- **Strategy Pattern**: Algoritmos intercambi√°veis
- **Observer Pattern**: Notifica√ß√µes de eventos

### Princ√≠pios Arquiteturais

#### SOLID Principles

1. **Single Responsibility Principle (SRP)**
   ```python
   # ‚úÖ Correto: Uma responsabilidade por classe
   class DocumentChunker:
       def chunk_document(self, document: Document) -> List[Chunk]:
           pass
   
   class EmbeddingGenerator:
       def generate_embeddings(self, chunks: List[Chunk]) -> List[Embedding]:
           pass
   ```

2. **Open/Closed Principle (OCP)**
   ```python
   # ‚úÖ Aberto para extens√£o, fechado para modifica√ß√£o
   class EmbeddingProvider(ABC):
       @abstractmethod
       def generate_embedding(self, text: str) -> List[float]:
           pass
   
   class OllamaEmbeddingProvider(EmbeddingProvider):
       def generate_embedding(self, text: str) -> List[float]:
           # Implementa√ß√£o espec√≠fica Ollama
           pass
   ```

3. **Liskov Substitution Principle (LSP)**
   ```python
   # ‚úÖ Subtipos devem ser substitu√≠veis
   def process_documents(provider: EmbeddingProvider, docs: List[Document]):
       # Funciona com qualquer implementa√ß√£o de EmbeddingProvider
       pass
   ```

4. **Interface Segregation Principle (ISP)**
   ```python
   # ‚úÖ Interfaces espec√≠ficas e coesas
   class Readable(Protocol):
       def read(self) -> str: pass
   
   class Writable(Protocol):
       def write(self, content: str) -> None: pass
   ```

5. **Dependency Inversion Principle (DIP)**
   ```python
   # ‚úÖ Depend√™ncia de abstra√ß√µes, n√£o de concretions
   class RAGQueryUseCase:
       def __init__(self, 
                    vector_store: VectorStoreRepository,
                    llm_service: LLMService):
           self._vector_store = vector_store
           self._llm_service = llm_service
   ```

#### Dependency Injection

```python
# src/infrastructure/di/container.py
from dependency_injector import containers, providers

class Container(containers.DeclarativeContainer):
    # Configura√ß√µes
    config = providers.Configuration()
    
    # Infrastructure
    neo4j_client = providers.Singleton(
        Neo4jClient,
        uri=config.neo4j.uri,
        username=config.neo4j.username,
        password=config.neo4j.password
    )
    
    ollama_client = providers.Singleton(
        OllamaClient,
        base_url=config.ollama.base_url
    )
    
    # Repositories
    document_repository = providers.Factory(
        Neo4jDocumentRepository,
        client=neo4j_client
    )
    
    # Services
    embedding_service = providers.Factory(
        OllamaEmbeddingService,
        client=ollama_client
    )
    
    # Use Cases
    rag_query_use_case = providers.Factory(
        RAGQueryUseCase,
        document_repository=document_repository,
        embedding_service=embedding_service
    )
```

### Padr√µes de Design Aplicados

#### 1. Repository Pattern
```python
class DocumentRepository(ABC):
    @abstractmethod
    async def save(self, document: Document) -> DocumentId:
        pass
    
    @abstractmethod
    async def find_by_id(self, doc_id: DocumentId) -> Optional[Document]:
        pass
    
    @abstractmethod
    async def find_similar(self, embedding: List[float], limit: int) -> List[Document]:
        pass
```

#### 2. Factory Pattern
```python
class EmbeddingProviderFactory:
    @staticmethod
    def create(provider_type: str) -> EmbeddingProvider:
        if provider_type == "ollama":
            return OllamaEmbeddingProvider()
        elif provider_type == "openai":
            return OpenAIEmbeddingProvider()
        raise ValueError(f"Unknown provider: {provider_type}")
```

#### 3. Strategy Pattern
```python
class ChunkingStrategy(ABC):
    @abstractmethod
    def chunk(self, text: str) -> List[str]:
        pass

class RecursiveChunkingStrategy(ChunkingStrategy):
    def chunk(self, text: str) -> List[str]:
        # Implementa√ß√£o recursiva
        pass

class SentenceChunkingStrategy(ChunkingStrategy):
    def chunk(self, text: str) -> List[str]:
        # Implementa√ß√£o por senten√ßas
        pass
```

#### 4. Observer Pattern
```python
class DomainEvent:
    def __init__(self, event_type: str, data: dict):
        self.event_type = event_type
        self.data = data
        self.timestamp = datetime.utcnow()

class EventBus:
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
    
    def subscribe(self, event_type: str, handler: EventHandler):
        self._handlers.setdefault(event_type, []).append(handler)
    
    async def publish(self, event: DomainEvent):
        for handler in self._handlers.get(event.event_type, []):
            await handler.handle(event)
```

### Fluxos de Dados

#### 1. Fluxo de Ingest√£o de Documentos
```mermaid
sequenceDiagram
    participant UI as Streamlit UI
    participant UC as Document Ingestion UC
    participant DS as Domain Service
    participant REPO as Repository
    participant NEO as Neo4j
    participant OLL as Ollama
    
    UI->>UC: upload_document(file)
    UC->>DS: process_document(content)
    DS->>DS: chunk_text()
    DS->>OLL: generate_embeddings(chunks)
    OLL-->>DS: embeddings
    DS->>REPO: save_document(doc, embeddings)
    REPO->>NEO: persist(document, vectors)
    NEO-->>REPO: document_id
    REPO-->>UC: document_id
    UC-->>UI: success(document_id)
```

#### 2. Fluxo de Consulta RAG
```mermaid
sequenceDiagram
    participant API as FastAPI
    participant UC as RAG Query UC
    participant EMB as Embedding Service
    participant REPO as Vector Repository
    participant LLM as LLM Service
    
    API->>UC: execute_query(question)
    UC->>EMB: embed_query(question)
    EMB-->>UC: query_embedding
    UC->>REPO: find_similar(embedding, k=5)
    REPO-->>UC: relevant_chunks
    UC->>LLM: generate_response(question, context)
    LLM-->>UC: generated_answer
    UC-->>API: query_result
```

### Tratamento de Erros

#### Hierarquia de Exce√ß√µes
```python
class RAGSystemError(Exception):
    """Exce√ß√£o base do sistema"""
    pass

class DomainError(RAGSystemError):
    """Erros de dom√≠nio/neg√≥cio"""
    pass

class InfrastructureError(RAGSystemError):
    """Erros de infraestrutura"""
    pass

class DocumentNotFoundError(DomainError):
    """Documento n√£o encontrado"""
    pass

class EmbeddingGenerationError(InfrastructureError):
    """Erro na gera√ß√£o de embeddings"""
    pass
```

#### Error Handling Strategy
```python
class ErrorHandler:
    @staticmethod
    async def handle_with_retry(
        func: Callable,
        max_retries: int = 3,
        backoff_factor: float = 1.0
    ):
        for attempt in range(max_retries):
            try:
                return await func()
            except InfrastructureError as e:
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(backoff_factor * (2 ** attempt))
```

### Performance e Escalabilidade

#### 1. Caching Strategy
```python
class CacheStrategy(ABC):
    @abstractmethod
    async def get(self, key: str) -> Optional[Any]:
        pass
    
    @abstractmethod
    async def set(self, key: str, value: Any, ttl: int = 3600):
        pass

class EmbeddingCache(CacheStrategy):
    """Cache espec√≠fico para embeddings"""
    
    def _generate_key(self, text: str) -> str:
        return f"embedding:{hashlib.md5(text.encode()).hexdigest()}"
```

#### 2. Connection Pooling
```python
class Neo4jConnectionPool:
    def __init__(self, uri: str, max_connections: int = 50):
        self._driver = GraphDatabase.driver(
            uri,
            max_connection_lifetime=3600,
            max_connection_pool_size=max_connections
        )
```

#### 3. Async Processing
```python
class AsyncDocumentProcessor:
    async def process_batch(self, documents: List[Document]) -> List[ProcessedDocument]:
        tasks = [self._process_single(doc) for doc in documents]
        return await asyncio.gather(*tasks, return_exceptions=True)
```

### Monitoramento e Observabilidade

#### Metrics Collection
```python
from prometheus_client import Counter, Histogram, Gauge

# M√©tricas de neg√≥cio
documents_ingested = Counter('documents_ingested_total', 'Total documents ingested')
queries_executed = Counter('queries_executed_total', 'Total queries executed')
query_latency = Histogram('query_latency_seconds', 'Query execution latency')

# M√©tricas t√©cnicas
active_connections = Gauge('neo4j_connections_active', 'Active Neo4j connections')
embedding_generation_time = Histogram('embedding_generation_seconds', 'Embedding generation time')
```

#### Health Checks
```python
class HealthChecker:
    async def check_neo4j(self) -> HealthStatus:
        try:
            async with self._neo4j.session() as session:
                await session.run("RETURN 1")
            return HealthStatus.HEALTHY
        except Exception:
            return HealthStatus.UNHEALTHY
    
    async def check_ollama(self) -> HealthStatus:
        try:
            response = await self._ollama.list_models()
            return HealthStatus.HEALTHY if response else HealthStatus.UNHEALTHY
        except Exception:
            return HealthStatus.UNHEALTHY
```

### Testes

#### Estrutura de Testes
```
tests/
‚îú‚îÄ‚îÄ unit/              # Testes unit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îú‚îÄ‚îÄ integration/       # Testes de integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îî‚îÄ‚îÄ external_services/
‚îú‚îÄ‚îÄ e2e/              # Testes end-to-end
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ ui/
‚îî‚îÄ‚îÄ fixtures/         # Dados de teste
    ‚îú‚îÄ‚îÄ documents/
    ‚îî‚îÄ‚îÄ embeddings/
```

#### Test Doubles
```python
class MockEmbeddingService(EmbeddingService):
    def __init__(self, fixed_embedding: List[float]):
        self._fixed_embedding = fixed_embedding
    
    async def generate_embedding(self, text: str) -> List[float]:
        return self._fixed_embedding

class InMemoryDocumentRepository(DocumentRepository):
    def __init__(self):
        self._documents: Dict[DocumentId, Document] = {}
    
    async def save(self, document: Document) -> DocumentId:
        doc_id = DocumentId.generate()
        self._documents[doc_id] = document
        return doc_id
```

Esta arquitetura garante um sistema robusto, test√°vel e escal√°vel, seguindo as melhores pr√°ticas de engenharia de software.