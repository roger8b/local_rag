## Refinamento Colaborativo: Hist√≥ria da Fase 4.1: Implementa√ß√£o do Provedor de Embedding Remoto (OpenAI)

---
### Hist√≥ria 1: Finalizar Implementa√ß√£o do Provedor de Embedding OpenAI

* **Tipo:** Funcional
* **Problema:** A interface do usu√°rio permite selecionar OpenAI como provedor de embeddings, mas o backend n√£o processa essa escolha, utilizando sempre o provedor local (Ollama).

#### Parte 1: Especifica√ß√£o Funcional (Vis√£o do Product Owner)
* **Hist√≥ria de Usu√°rio:** Como um Usu√°rio, eu quero que a minha escolha de usar o provedor de embeddings "OpenAI" na tela de upload seja respeitada pelo sistema, para que eu possa me beneficiar de um processamento de documentos mais r√°pido quando necess√°rio.
* **Requisitos / Detalhes:**
    * A interface de upload de documentos deve enviar a escolha do provedor de embedding (Ollama ou OpenAI) para o backend.
    * A sele√ß√£o do provedor na interface deve ser refatorada para ser mais escal√°vel, permitindo a f√°cil adi√ß√£o de novos provedores (como Gemini) no futuro.
    * O endpoint da API de ingest√£o de documentos deve ser capaz de receber e interpretar essa escolha.
    * Se "OpenAI" for escolhido, o servi√ßo de ingest√£o deve usar a API da OpenAI para gerar os embeddings.
    * Se "Local (Ollama)" for escolhido, o comportamento atual deve ser mantido.
    * A configura√ß√£o da chave de API da OpenAI (`OPENAI_API_KEY`) deve ser usada pelo backend ao se comunicar com a OpenAI.
    * O sistema deve fornecer feedback claro ao usu√°rio caso a API da OpenAI seja escolhida mas a chave n√£o esteja configurada ou seja inv√°lida.
* **Crit√©rios de Aceite (ACs):**
    * **AC 1:** Dado que a chave da API da OpenAI est√° configurada corretamente, quando eu seleciono "‚òÅÔ∏è OpenAI" na UI e fa√ßo o upload de um documento, ent√£o o sistema deve usar a API da OpenAI para gerar os embeddings, e o documento deve ser salvo com sucesso.
    * **AC 2:** Dado que a chave da API da OpenAI **n√£o** est√° configurada, quando eu seleciono "‚òÅÔ∏è OpenAI" e tento fazer o upload, ent√£o a API deve retornar um erro `400 Bad Request` com uma mensagem clara indicando que a chave √© necess√°ria.
    * **AC 3:** Quando eu seleciono "üè† Local (Ollama)" e fa√ßo o upload de um documento, ent√£o o sistema deve usar o Ollama para gerar os embeddings, como j√° funciona atualmente.
* **Defini√ß√£o de 'Pronto' (DoD Checklist):**
    * [ ] C√≥digo revisado por um par (PR aprovado).
    * [ ] Testes de integra√ß√£o escritos para o servi√ßo de ingest√£o, cobrindo ambos os provedores (Ollama e OpenAI).
    * [ ] Funcionalidade validada manualmente atrav√©s da interface do usu√°rio.
    * [ ] A documenta√ß√£o (README.md) foi atualizada para refletir a funcionalidade completa.

#### Parte 2: Especifica√ß√£o T√©cnica (Vis√£o do Engenheiro)
* **Abordagem T√©cnica Proposta:**
    * Modificaremos a cadeia de chamadas desde o cliente da API at√© o servi√ßo de ingest√£o para passar um novo par√¢metro que especifica o provedor de embedding. Uma l√≥gica condicional no servi√ßo de ingest√£o selecionar√° o cliente apropriado (Ollama ou um novo cliente OpenAI) para gerar os vetores.
* **Frontend (UI):**
    * - **`src/ui/pages/document_upload.py`**: Refatorar o componente de sele√ß√£o (`st.radio`) para ser gerado dinamicamente a partir de uma estrutura de dados (ex: um dicion√°rio de provedores). A chamada `rag_client.upload_file` deve ser modificada para incluir a chave do provedor selecionado (ex: 'ollama', 'openai').
* **API Client:**
    * - **`src/api/client.py`**: O m√©todo `upload_file` precisa ser atualizado para aceitar o par√¢metro `embedding_provider` e envi√°-lo no corpo da requisi√ß√£o para a API.
* **Backend:**
    * - **API (`src/api/routes.py`):** O endpoint de upload (`/upload`) deve ser atualizado para aceitar um campo opcional no corpo da requisi√ß√£o, por exemplo, `embedding_provider: str = "ollama"`.
    * - **Servi√ßo de Ingest√£o (`src/application/services/ingestion_service.py`):**
        * O m√©todo `ingest_from_content` (ou similar) deve receber o par√¢metro `embedding_provider`.
        * A l√≥gica do m√©todo `_generate_embeddings` deve ser refatorada. Em vez de chamar diretamente o c√≥digo do Ollama, ele deve delegar a gera√ß√£o para uma outra classe/fun√ß√£o baseada no valor de `embedding_provider`.
        * Criar uma nova implementa√ß√£o para gerar embeddings via OpenAI, que ser√° chamada se `embedding_provider == "openai"`. Esta nova implementa√ß√£o precisar√° ler a `OPENAI_API_KEY` das configura√ß√µes.
* **Banco de Dados:**
    * - Nenhuma altera√ß√£o de schema √© necess√°ria. Os embeddings gerados pela OpenAI devem ter a mesma dimens√£o que os do Ollama, ou o √≠ndice vetorial precisar√° ser reconfigurado (ponto a ser verificado).
* **Quest√µes em Aberto / Riscos:**
    * - **Dimens√£o dos Embeddings:** √â crucial garantir que o modelo de embedding da OpenAI (ex: `text-embedding-3-small`) gere vetores com a mesma dimens√£o configurada no √≠ndice do Neo4j (atualmente 256 para `nomic-embed-text`). Se n√£o for o caso, ser√° necess√°rio um plano de migra√ß√£o ou uma configura√ß√£o mais complexa. **A√ß√£o:** Verificar a dimens√£o do modelo da OpenAI e ajustar o c√≥digo ou a configura√ß√£o do √≠ndice.
    * - **Gerenciamento de Erros:** A comunica√ß√£o com a API da OpenAI pode falhar por diversos motivos (chave inv√°lida, cota excedida, etc.). O tratamento de erros precisa ser robusto.
    * - **Custo:** O uso da API da OpenAI gera custos. A interface deve deixar isso claro para o usu√°rio. (J√° est√° parcialmente feito).
