#!/usr/bin/env python3
"""
Script para verificar se OpenAI e Gemini funcionarÃ£o quando implementados
"""
import asyncio


async def test_openai_readiness():
    """Testa se OpenAI funcionarÃ¡ quando implementado"""
    print("ğŸ” Testando se OpenAI funcionarÃ¡ quando implementado...")
    
    try:
        # Testar biblioteca
        import openai
        from src.config.settings import settings
        
        if not settings.openai_api_key:
            print("âŒ OPENAI_API_KEY nÃ£o configurada")
            return False
            
        # Testar conectividade
        client = openai.OpenAI(api_key=settings.openai_api_key)
        
        # Teste 1: Listar modelos
        models = client.models.list()
        print(f"âœ… OpenAI conectividade OK - {len(models.data)} modelos")
        
        # Teste 2: Testar chat completion (similar ao que seria implementado)
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Modelo recomendado para o projeto
            messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
                {"role": "user", "content": "Diga apenas 'teste' como resposta."}
            ],
            max_tokens=10
        )
        
        result = response.choices[0].message.content
        print(f"âœ… Chat Completion funcionando: '{result}'")
        
        # Teste 3: Testar embeddings
        embedding_response = client.embeddings.create(
            model="text-embedding-3-small",
            input="texto de teste"
        )
        
        embedding = embedding_response.data[0].embedding
        print(f"âœ… Embeddings funcionando: {len(embedding)} dimensÃµes")
        
        return True
        
    except ImportError:
        print("âŒ Biblioteca openai nÃ£o instalada")
        print("   Instale com: pip install openai")
        return False
    except Exception as e:
        print(f"âŒ Erro OpenAI: {e}")
        return False


async def test_gemini_readiness():
    """Testa se Gemini funcionarÃ¡ quando implementado"""
    print("ğŸ” Testando se Gemini funcionarÃ¡ quando implementado...")
    
    try:
        # Testar biblioteca
        import google.generativeai as genai
        from src.config.settings import settings
        
        if not settings.google_api_key:
            print("âŒ GOOGLE_API_KEY nÃ£o configurada")
            return False
            
        # Configurar API
        genai.configure(api_key=settings.google_api_key)
        
        # Teste 1: Listar modelos
        models = list(genai.list_models())
        print(f"âœ… Gemini conectividade OK - {len(models)} modelos")
        
        # Teste 2: Testar geraÃ§Ã£o (similar ao que seria implementado)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content("Diga apenas 'teste' como resposta.")
        
        result = response.text
        print(f"âœ… GeraÃ§Ã£o funcionando: '{result.strip()}'")
        
        return True
        
    except ImportError:
        print("âŒ Biblioteca google-generativeai nÃ£o instalada")
        print("   Instale com: pip install google-generativeai")
        return False
    except Exception as e:
        print(f"âŒ Erro Gemini: {e}")
        return False


def show_implementation_plan():
    """Mostra o que precisa ser implementado"""
    print("\nğŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO")
    print("=" * 50)
    
    print("\nğŸ”§ Para OpenAI Provider:")
    print("1. Instalar biblioteca: pip install openai")
    print("2. Criar src/generation/providers/openai.py")
    print("3. Implementar classe OpenAIProvider(LLMProvider)")
    print("4. Atualizar factory em generator.py")
    print("5. Adicionar testes")
    
    print("\nğŸ”§ Para Gemini Provider:")
    print("1. Instalar biblioteca: pip install google-generativeai")
    print("2. Criar src/generation/providers/gemini.py")
    print("3. Implementar classe GeminiProvider(LLMProvider)")
    print("4. Atualizar factory em generator.py")
    print("5. Adicionar testes")
    
    print("\nğŸ“ Template de implementaÃ§Ã£o:")
    print("""
class OpenAIProvider(LLMProvider):
    def __init__(self):
        self.client = openai.OpenAI(api_key=settings.openai_api_key)
        self.model = "gpt-4o-mini"
    
    async def generate_response(self, question: str, sources: List[DocumentSource]) -> str:
        prompt = self._build_prompt(question, sources)
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
""")


async def main():
    """Executa todos os testes de readiness"""
    print("ğŸš€ VERIFICAÃ‡ÃƒO DE READINESS PARA PROVIDERS FUTUROS")
    print("=" * 60)
    
    # Testar OpenAI
    print("\nğŸ¤– OPENAI")
    print("-" * 30)
    openai_ready = await test_openai_readiness()
    
    # Testar Gemini
    print("\nğŸ§  GEMINI")
    print("-" * 30)
    gemini_ready = await test_gemini_readiness()
    
    # Mostrar resumo
    print("\nğŸ“Š RESUMO FINAL")
    print("=" * 30)
    print(f"OpenAI pronto: {'âœ… SIM' if openai_ready else 'âŒ NÃƒO'}")
    print(f"Gemini pronto: {'âœ… SIM' if gemini_ready else 'âŒ NÃƒO'}")
    
    if openai_ready and gemini_ready:
        print("\nğŸ‰ AMBOS PROVIDERS ESTÃƒO PRONTOS!")
        print("   A implementaÃ§Ã£o funcionarÃ¡ quando o cÃ³digo for criado.")
    elif openai_ready or gemini_ready:
        print(f"\nâš ï¸  {'OpenAI' if openai_ready else 'Gemini'} estÃ¡ pronto")
        print("   O outro provider precisa de configuraÃ§Ã£o.")
    else:
        print("\nâŒ NENHUM PROVIDER EXTERNO ESTÃ PRONTO")
        print("   Mas Ollama estÃ¡ funcionando!")
    
    # Mostrar plano de implementaÃ§Ã£o
    show_implementation_plan()


if __name__ == "__main__":
    asyncio.run(main())