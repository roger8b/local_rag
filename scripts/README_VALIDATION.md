# Scripts de Valida√ß√£o - Local RAG System

Esta pasta cont√©m scripts para validar o funcionamento do sistema Local RAG atrav√©s de chamadas reais √†s APIs.

## üìú Scripts Dispon√≠veis

### 1. `test_workflow.py` - Fluxo Completo
**Fluxo**: Upload ‚Üí Consultas RAG ‚Üí Limpeza

Testa o funcionamento end-to-end do sistema RAG:
- Upload e processamento de documento
- M√∫ltiplas consultas em linguagem natural  
- Verifica√ß√£o de respostas e fontes
- Limpeza e status do sistema

```bash
# Uso b√°sico
python scripts/test_workflow.py

# Com URL customizada
python scripts/test_workflow.py --url http://localhost:8001

# Modo r√°pido (menos consultas)
python scripts/test_workflow.py --quick
```

### 2. `test_schema_flow.py` - Fluxo Schema API
**Fluxo**: Upload ‚Üí Infer√™ncia de Schema ‚Üí Limpeza

Foca especificamente nas funcionalidades de schema (Hist√≥rias 6-8):
- Upload de documento com estat√≠sticas detalhadas
- Infer√™ncia de schema com controle percentual
- Sele√ß√£o din√¢mica de provider LLM
- Gerenciamento de cache com TTL

```bash
# Uso b√°sico
python scripts/test_schema_flow.py

# Com URL customizada  
python scripts/test_schema_flow.py --url http://localhost:8001
```

### 3. `api_validation.py` - Valida√ß√£o Completa
**Fluxo**: Todos os endpoints + Relat√≥rio

Valida√ß√£o abrangente de todas as APIs do sistema:
- Testa todos os endpoints dispon√≠veis
- Gera relat√≥rio detalhado em JSON
- M√©tricas de performance e confiabilidade

```bash
# Valida√ß√£o completa
python scripts/api_validation.py

# Salvar relat√≥rio
python scripts/api_validation.py --output validation_report.json

# Sem limpeza de dados de teste
python scripts/api_validation.py --no-cleanup

# Modo silencioso
python scripts/api_validation.py --quiet
```

## üöÄ Prepara√ß√£o

### Pr√©-requisitos
1. **API em execu√ß√£o**:
   ```bash
   python run_api.py
   ```

2. **Depend√™ncias instaladas**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Servi√ßos opcionais** (para funcionalidade completa):
   - Ollama rodando localmente
   - Neo4j configurado
   - Chaves de API (OpenAI/Gemini) se usar providers externos

### Verifica√ß√£o R√°pida
```bash
# Teste de conectividade b√°sica
curl http://localhost:8000/api/v1/health

# Ou use o script de teste r√°pido
python scripts/test_schema_flow.py
```

## üìä Resultados Esperados

### ‚úÖ Sucesso
- **C√≥digos de sa√≠da**: 0
- **Logs verdes**: Opera√ß√µes bem-sucedidas
- **M√©tricas**: Tempos de resposta < 2s
- **Taxa de sucesso**: > 90%

### ‚ùå Falhas Comuns
- **C√≥digo 1**: Falhas funcionais nos testes
- **C√≥digo 2**: Interrup√ß√£o do usu√°rio (Ctrl+C)
- **C√≥digo 3**: Erros de conex√£o/configura√ß√£o

### üîß Troubleshooting
1. **Connection Error**: 
   - Verificar se API est√° rodando
   - Confirmar URL correta

2. **Timeouts**:
   - Verificar se Ollama est√° respondendo
   - Verificar conex√£o Neo4j

3. **Provider Errors**:
   - Verificar chaves de API
   - Verificar configura√ß√£o de providers

## üìà M√©tricas Monitoradas

### Performance
- **Tempo de upload**: Normalmente < 1s
- **Tempo de infer√™ncia**: 1-3s (dependendo do modelo)
- **Tempo de consulta**: 2-5s (dependendo da complexidade)

### Funcionalidade  
- **Taxa de upload**: 100% esperado
- **Taxa de infer√™ncia**: > 95% esperado
- **Taxa de consultas**: > 90% esperado

### Recursos
- **Uso de mem√≥ria**: Monitorado no cache
- **Chunks criados**: Validado por documento
- **Limpeza**: Confirma√ß√£o de remo√ß√£o

## üõ†Ô∏è Personaliza√ß√£o

### Modificar Documentos de Teste
Edite as vari√°veis `document_content` nos scripts para testar com seus pr√≥prios dados.

### Adicionar Novos Testes
1. Crie nova fun√ß√£o `test_nova_funcionalidade()`
2. Adicione √† sequ√™ncia no m√©todo `run_flow()`
3. Configure logging apropriado

### Configurar Providers
Modifique os payloads dos testes para usar diferentes providers:
```python
payload = {
    "text": "seu texto aqui",
    "llm_provider": "openai",  # ollama, openai, gemini
    "llm_model": "gpt-4o-mini"
}
```

## üìù Exemplo de Uso Completo

```bash
# 1. Iniciar a API
python run_api.py &

# 2. Aguardar alguns segundos para startup

# 3. Executar teste b√°sico
python scripts/test_schema_flow.py

# 4. Se sucesso, executar teste completo
python scripts/test_workflow.py

# 5. Para valida√ß√£o abrangente  
python scripts/api_validation.py --output report.json

# 6. Verificar relat√≥rio
cat report.json | jq '.summary'
```

## üéØ Casos de Uso

### Desenvolvimento
- Validar mudan√ßas ap√≥s implementa√ß√£o
- Testar novos providers/modelos
- Debug de problemas espec√≠ficos

### Deploy
- Smoke tests ap√≥s deploy
- Valida√ß√£o de sa√∫de do sistema
- Monitoramento de performance

### CI/CD
- Testes automatizados em pipeline
- Valida√ß√£o de qualidade
- Relat√≥rios de regress√£o

---

üí° **Dica**: Execute `test_schema_flow.py` primeiro para valida√ß√£o r√°pida, depois `test_workflow.py` para teste completo.